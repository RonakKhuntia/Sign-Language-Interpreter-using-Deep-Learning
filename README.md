<h1>Sing Language Interpreter using Deep Learning I SDP-IH18 Project</h1>

<h2>Contributors</h2>

- [Ansuman Mohanty](https://github.com/Ansuman3152)

- [Rounak Kumar Khuntia](https://github.com/RonakKhuntia)

- [Priyadarshini Nayak](https://github.com/priyu1109)

- [Kumar Spandan Pattanayak](https://github.com/5p7Ro0t)

<h2>About</h2>

<b>" Sing Language Interpreter using Deep Learning "</b> is a part of our B.Tech Final Year SDP Project.The primary objective is to develop an accurate and efficient system capable of translating sign language gestures 
into text and audio, facilitating seamless interaction for the deaf and hard-of-hearing community. The system utilizes neural networks trained on extensive sign language datasets to recognize the 
intricate movements and expressions inherent in sign language. Computer vision techniques are employed to 
capture and interpret gestures accurately, ensuring a high level of precision in the translation process. 





https://github.com/RonakKhuntia/Sign-Language-Interpreter-using-Deep-Learning/assets/66641606/c71de96f-6bcc-47a3-af1d-a085f39684f6









<h2>Requirements</h2>

- mediapipe (requires a python version between 3.8 - 3.11)
  
- OpenCV

- numpy

- pyttsx3

<h2>Instructions</h2>

1.After cloning this repo, run the following command to install all dependencies

    pip install tensorflow opencv-python mediapipe scikit-learn matplotlib pyttsx3 numpy

2.Run the following command to launch the application

    python app.py

<br>
<p align="center">
<img src="https://github.com/RonakKhuntia/Sign-Language-Interpreter-using-Deep-Learning/blob/main/hand_signs.jpg" alt="hand signs">
</p>
